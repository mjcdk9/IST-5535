ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(200,300) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#400 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(300,400) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#500 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(400,500) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#100 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(0,100) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#200 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(100,200) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#300 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(200,300) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#400 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(300,400) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#500 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(400,500) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#100 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(0,100) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#200 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(100,200) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#300 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(200,300) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#400 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(300,400) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#500 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(400,500) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#print(df.original$review)
# Commented out for knitting purposes
df.original$is_short_review <- ifelse(nchar(df.original$review)<120,1,0)
#Short reviews found helpful or unhelpful
barplot(with(df.original, table(num_found_helpful, is_short_review)), main = "Short Reviews found Helpful or Unhelpful", col=1)
#Short reviews found funny
barplot(with(df.original, table(num_found_funny, is_short_review)), main = "Short Reviews found Funny or Unfunny", col=1)
#Set review is funny boolean
df.original$reviewIsFunny <- ifelse(df.original$num_found_funny>0,1,0)
table(df.original$reviewIsFunny)
ggplot(df.original, aes(x=reviewIsFunny, fill=num_found_helpful)) +
geom_bar(position=position_dodge()) +
coord_flip() +
labs(
title = "Relationship with Helpful/Unhelpful Reviews being found funny",
x = "Review is Funny",
y = "Num Helpful",
fill = "Region"
)
# Text Mining set was pulled from "https://www.hackerearth.com/practice/machine-learning/advanced-techniques/text-mining-feature-engineering-r/tutorial/"
library(data.table)
library(tm)
tdata <- df.original
tdata$review <- lapply(tdata$review, tolower)
text_corpus <- Corpus(VectorSource(tdata$review))
# Clean Corpus Data
dropword <- "br"
text_corpus <- tm_map(text_corpus, content_transformer(removeWords),dropword)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, content_transformer(removePunctuation))
text_corpus <- tm_map(text_corpus, content_transformer(removeNumbers))
text_corpus <- tm_map(text_corpus, content_transformer(removeWords), c(stopwords('english')))
text_corpus <- tm_map(text_corpus, content_transformer(stripWhitespace))
# Stem the document so all plural words are now counted as one word
text_corpus <- tm_map(text_corpus, stemDocument, language = "english")
#print(as.character(text_corpus[[1]]))
#text_corpus[[1]]$content
docterm_corpus <- DocumentTermMatrix(text_corpus)
dim(docterm_corpus)
new_docterm_corpus <- removeSparseTerms(docterm_corpus,sparse = 0.95)
dim(new_docterm_corpus)
#find frequent terms
colS <- colSums(as.matrix(new_docterm_corpus))
length(colS)
doc_features <- data.table(name = attributes(colS)$names, count = colS)
#most frequent and least frequent words
doc_features[order(-count)][1:10] #top 10 most frequent words
doc_features[order(count)][1:10] #least 10 frequent words
processed_data <- as.data.table(as.matrix(new_docterm_corpus))
text_dataset <- cbind(df.original, processed_data)
#head(text_dataset)
#Commented out for knitting purposes
library("qdap")
# First going to clean the data to be better used
#These are the two datasets. Text_mining_data includes the text mining information, while original_data does not. There for easier use in analysis comparison.
text_mining_data <- text_dataset
df.clean <- df.original
# Get word count, used for analysis later
text_mining_data$review_word_count <- word_count(text_mining_data$review)
df.clean$review_word_count <- word_count(df.clean$review)
# Change achievement_progress to just hold the achievement percentage as the other data is not helpful.
text_mining_data$achievement_progress <- text_mining_data$achievement_progress$num_achievements_percentage
df.clean$achievement_progress <- df.clean$achievement_progress$num_achievements_percentage
# Remove Unique Identifiers and variables that don't help in predictions
text_mining_data$profile_url <- NULL
text_mining_data$steam_id_number <- NULL
text_mining_data$orig_url <- NULL
text_mining_data$review_url <- NULL
text_mining_data$username <- NULL
text_mining_data$review <- NULL
text_mining_data$date_posted <- NULL
text_mining_data$date_updated <- NULL
text_mining_data$is_short_review <- factor(text_mining_data$is_short_review)
text_mining_data$reviewIsFunny <- factor(text_mining_data$reviewIsFunny)
text_mining_data$rating <- factor(text_mining_data$rating)
# Same for original data set
df.clean$profile_url <- NULL
df.clean$steam_id_number <- NULL
df.clean$orig_url <- NULL
df.clean$review_url <- NULL
df.clean$username <- NULL
df.clean$review <- NULL
df.clean$date_posted <- NULL
df.clean$date_updated <- NULL
df.clean$is_short_review <- factor(df.clean$reviewIsFunny)
df.clean$reviewIsFunny <- factor(df.clean$reviewIsFunny)
df.clean$rating <- factor(df.clean$rating)
# Replace NA values
df.clean$num_badges[is.na(df.clean$num_badges)]<-mean(df.clean$num_badges,na.rm=TRUE)
df.clean$achievement_progress[is.na(df.clean$achievement_progress)]<-mean(df.clean$achievement_progress,na.rm=TRUE)
df.clean$friend_player_level[is.na(df.clean$friend_player_level)]<-mean(df.clean$friend_player_level,na.rm=TRUE)
df.clean$num_friends[is.na(df.clean$num_friends)]<-mean(df.clean$num_friends,na.rm=TRUE)
df.clean$num_groups[is.na(df.clean$num_groups)]<-mean(df.clean$num_groups,na.rm=TRUE)
#50/50 split
splitdata <- sample(1:nrow(df.clean), nrow(df.clean)*0.50)
train <- df.clean[splitdata,]
test <- df.clean[-splitdata,]
dim(train)
#50/50 split text mining
splitminingdata <- sample(1:nrow(text_mining_data), nrow(text_mining_data)*0.50)
train_text <- text_mining_data[splitminingdata,]
test_text <- text_mining_data[-splitminingdata,]
dim(train_text)
#Set playtime to two categories, <200 hours and >200 hours
df.clean$playtime200hours <- ifelse(df.clean$total_game_hours<200,1,0)
#Plot
ggplot(df.clean, aes(x=playtime200hours, fill=review_word_count)) +
geom_bar(position=position_dodge()) +
coord_flip() +
labs(
title = "Relationship with Playtime and Review Wordcount",
x = "Playtime",
y = "Word Count",
fill = "Region"
)
library('caret')
# ToDo make sure this is predicting properly (i got docked on the homework)
#str(df.clean)
logit.fit.clean.train <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = train)
summary(logit.fit.clean.train)
logit.fit.clean.test <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = test)
logit.test_probs <- predict(logit.fit.clean.test, newdata = test, type="response")
#factor(ifelse(logit.test_probs > 0.5, "1", "0"))
levels(factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")))
confusionMatrix(factor(ifelse(logit.test_probs > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), positive="1")
#str(df.clean)
logit.fit.mining.train <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = train_text)
summary(logit.fit.mining.train)
logit.fit.mining.test <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = test_text)
logit.test_probs <- predict(logit.fit.mining.test, newdata = test_text, type="response")
#factor(ifelse(logit.test_probs > 0.5, "1", "0"))
levels(factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")))
confusionMatrix(factor(ifelse(logit.test_probs > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), positive="1")
# Model needs to be evaluated on Test Data Set
library("MASS")
lda.fit.clean <- lda(found_helpful_percentage ~ num_found_unhelpful + rating + num_friends + is_short_review, data = test)
lda.pred <- predict(lda.fit.clean)
lda.pred <- as.data.frame(do.call(cbind.data.frame, lda.pred))
confusionMatrix(factor(ifelse(as.numeric(lda.pred$class) > mean(as.numeric(lda.pred$class),na.rm=TRUE), "1","0")), factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1","0")), positive = "1")
lda.fit.clean.text <- lda(found_helpful_percentage ~ rating + reviewIsFunny, data = test_text)
lda.pred.text <- predict(lda.fit.clean.text)
# Trying to convert back to levels
lda.pred.text$class <- as.numeric(as.character(lda.pred.text$class))
summary(lda.pred.text$class)
#lda.pred.text <- as.data.frame(do.call(cbind.data.frame, lda.pred.text))
#class(lda.pred.text)
# Going from a factor to as.numeric return 207 only. This is wrong. Fix it
levels(factor(ifelse(as.numeric(lda.pred.text$class) > mean(as.numeric(lda.pred.text$class),na.rm=TRUE), "1","0")))
levels(factor(ifelse(test_text$found_helpful_percentage > mean(test_text$found_helpful_percentage,na.rm=TRUE), "1","0")))
confusionMatrix(factor(ifelse(as.numeric(lda.pred.text$class) > mean(as.numeric(lda.pred.text$class),na.rm=TRUE), "1","0")), factor(ifelse(test_text$found_helpful_percentage > mean(test_text$found_helpful_percentage,na.rm=TRUE), "1","0")), positive = "1")
# Model needs to be evaluated on Test Data Set
test <- droplevels(test$rating)
qda.fit.clean <- qda(found_helpful_percentage ~ num_found_unhelpful + rating + num_friends + is_short_review, data = test)
# Model needs to be evaluated on Test Data Set
test <- droplevels(test$rating)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
#install.packages("jsonlite") Will need this
#install.packages("tm") will need this for text mining
#install.packages("qdap") used for word_count function
library(jsonlite)
The_Elder_Scrolls_JSON <- "The_Elder_Scrolls_V.jsonlines"
df.original <- stream_in(file(The_Elder_Scrolls_JSON))
nrow(df.original)
ncol(df.original)
head(df.original)
library(ggplot2)
#100 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(0,100) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#200 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(100,200) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (200 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#300 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(200,300) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#400 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(300,400) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#500 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_helpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(400,500) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found helpful"
)
#100 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(0,100) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#200 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(100,200) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#300 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(200,300) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#400 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(300,400) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#500 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_funny)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(400,500) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found funny"
)
#100 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(0,100) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#200 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(100,200) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#300 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(200,300) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#400 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(300,400) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#500 hours
ggplot(df.original, aes(x=total_game_hours, fill=num_found_unhelpful)) + geom_bar(position=position_dodge()) + coord_flip() + xlim(400,500) + ylim(0,10) +
labs(
title = "Distribution of game hours and helpful reviews (100 hours)",
x = "Total game hours",
y = "Reviews found unhelpful"
)
#print(df.original$review)
# Commented out for knitting purposes
df.original$is_short_review <- ifelse(nchar(df.original$review)<120,1,0)
#Short reviews found helpful or unhelpful
barplot(with(df.original, table(num_found_helpful, is_short_review)), main = "Short Reviews found Helpful or Unhelpful", col=1)
#Short reviews found funny
barplot(with(df.original, table(num_found_funny, is_short_review)), main = "Short Reviews found Funny or Unfunny", col=1)
#Set review is funny boolean
df.original$reviewIsFunny <- ifelse(df.original$num_found_funny>0,1,0)
table(df.original$reviewIsFunny)
ggplot(df.original, aes(x=reviewIsFunny, fill=num_found_helpful)) +
geom_bar(position=position_dodge()) +
coord_flip() +
labs(
title = "Relationship with Helpful/Unhelpful Reviews being found funny",
x = "Review is Funny",
y = "Num Helpful",
fill = "Region"
)
# Text Mining set was pulled from "https://www.hackerearth.com/practice/machine-learning/advanced-techniques/text-mining-feature-engineering-r/tutorial/"
library(data.table)
library(tm)
tdata <- df.original
tdata$review <- lapply(tdata$review, tolower)
text_corpus <- Corpus(VectorSource(tdata$review))
# Clean Corpus Data
dropword <- "br"
text_corpus <- tm_map(text_corpus, content_transformer(removeWords),dropword)
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, content_transformer(removePunctuation))
text_corpus <- tm_map(text_corpus, content_transformer(removeNumbers))
text_corpus <- tm_map(text_corpus, content_transformer(removeWords), c(stopwords('english')))
text_corpus <- tm_map(text_corpus, content_transformer(stripWhitespace))
# Stem the document so all plural words are now counted as one word
text_corpus <- tm_map(text_corpus, stemDocument, language = "english")
#print(as.character(text_corpus[[1]]))
#text_corpus[[1]]$content
docterm_corpus <- DocumentTermMatrix(text_corpus)
dim(docterm_corpus)
new_docterm_corpus <- removeSparseTerms(docterm_corpus,sparse = 0.95)
dim(new_docterm_corpus)
#find frequent terms
colS <- colSums(as.matrix(new_docterm_corpus))
length(colS)
doc_features <- data.table(name = attributes(colS)$names, count = colS)
#most frequent and least frequent words
doc_features[order(-count)][1:10] #top 10 most frequent words
doc_features[order(count)][1:10] #least 10 frequent words
processed_data <- as.data.table(as.matrix(new_docterm_corpus))
text_dataset <- cbind(df.original, processed_data)
#head(text_dataset)
#Commented out for knitting purposes
library("qdap")
# First going to clean the data to be better used
#These are the two datasets. Text_mining_data includes the text mining information, while original_data does not. There for easier use in analysis comparison.
text_mining_data <- text_dataset
df.clean <- df.original
# Get word count, used for analysis later
text_mining_data$review_word_count <- word_count(text_mining_data$review)
df.clean$review_word_count <- word_count(df.clean$review)
# Change achievement_progress to just hold the achievement percentage as the other data is not helpful.
text_mining_data$achievement_progress <- text_mining_data$achievement_progress$num_achievements_percentage
df.clean$achievement_progress <- df.clean$achievement_progress$num_achievements_percentage
# Remove Unique Identifiers and variables that don't help in predictions
text_mining_data$profile_url <- NULL
text_mining_data$steam_id_number <- NULL
text_mining_data$orig_url <- NULL
text_mining_data$review_url <- NULL
text_mining_data$username <- NULL
text_mining_data$review <- NULL
text_mining_data$date_posted <- NULL
text_mining_data$date_updated <- NULL
text_mining_data$is_short_review <- factor(text_mining_data$is_short_review)
text_mining_data$reviewIsFunny <- factor(text_mining_data$reviewIsFunny)
text_mining_data$rating <- factor(text_mining_data$rating)
# Same for original data set
df.clean$profile_url <- NULL
df.clean$steam_id_number <- NULL
df.clean$orig_url <- NULL
df.clean$review_url <- NULL
df.clean$username <- NULL
df.clean$review <- NULL
df.clean$date_posted <- NULL
df.clean$date_updated <- NULL
df.clean$is_short_review <- factor(df.clean$reviewIsFunny)
df.clean$reviewIsFunny <- factor(df.clean$reviewIsFunny)
df.clean$rating <- factor(df.clean$rating)
# Replace NA values
df.clean$num_badges[is.na(df.clean$num_badges)]<-mean(df.clean$num_badges,na.rm=TRUE)
df.clean$achievement_progress[is.na(df.clean$achievement_progress)]<-mean(df.clean$achievement_progress,na.rm=TRUE)
df.clean$friend_player_level[is.na(df.clean$friend_player_level)]<-mean(df.clean$friend_player_level,na.rm=TRUE)
df.clean$num_friends[is.na(df.clean$num_friends)]<-mean(df.clean$num_friends,na.rm=TRUE)
df.clean$num_groups[is.na(df.clean$num_groups)]<-mean(df.clean$num_groups,na.rm=TRUE)
#50/50 split
splitdata <- sample(1:nrow(df.clean), nrow(df.clean)*0.50)
train <- df.clean[splitdata,]
test <- df.clean[-splitdata,]
dim(train)
#50/50 split text mining
splitminingdata <- sample(1:nrow(text_mining_data), nrow(text_mining_data)*0.50)
train_text <- text_mining_data[splitminingdata,]
test_text <- text_mining_data[-splitminingdata,]
dim(train_text)
#Set playtime to two categories, <200 hours and >200 hours
df.clean$playtime200hours <- ifelse(df.clean$total_game_hours<200,1,0)
#Plot
ggplot(df.clean, aes(x=playtime200hours, fill=review_word_count)) +
geom_bar(position=position_dodge()) +
coord_flip() +
labs(
title = "Relationship with Playtime and Review Wordcount",
x = "Playtime",
y = "Word Count",
fill = "Region"
)
library('caret')
# ToDo make sure this is predicting properly (i got docked on the homework)
#str(df.clean)
logit.fit.clean.train <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = train)
summary(logit.fit.clean.train)
logit.fit.clean.test <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = test)
logit.test_probs <- predict(logit.fit.clean.test, newdata = test, type="response")
#factor(ifelse(logit.test_probs > 0.5, "1", "0"))
levels(factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")))
confusionMatrix(factor(ifelse(logit.test_probs > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), positive="1")
#str(df.clean)
logit.fit.mining.train <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = train_text)
summary(logit.fit.mining.train)
logit.fit.mining.test <- glm(found_helpful_percentage ~ ., family = binomial(link='logit'), data = test_text)
logit.test_probs <- predict(logit.fit.mining.test, newdata = test_text, type="response")
#factor(ifelse(logit.test_probs > 0.5, "1", "0"))
levels(factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")))
confusionMatrix(factor(ifelse(logit.test_probs > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1", "0")), positive="1")
# Model needs to be evaluated on Test Data Set
library("MASS")
lda.fit.clean <- lda(found_helpful_percentage ~ num_found_unhelpful + rating + num_friends + is_short_review, data = test)
lda.pred <- predict(lda.fit.clean)
lda.pred <- as.data.frame(do.call(cbind.data.frame, lda.pred))
confusionMatrix(factor(ifelse(as.numeric(lda.pred$class) > mean(as.numeric(lda.pred$class),na.rm=TRUE), "1","0")), factor(ifelse(test$found_helpful_percentage > mean(test$found_helpful_percentage,na.rm=TRUE), "1","0")), positive = "1")
lda.fit.clean.text <- lda(found_helpful_percentage ~ rating + reviewIsFunny, data = test_text)
lda.pred.text <- predict(lda.fit.clean.text)
# Trying to convert back to levels
lda.pred.text$class <- as.numeric(as.character(lda.pred.text$class))
summary(lda.pred.text$class)
#lda.pred.text <- as.data.frame(do.call(cbind.data.frame, lda.pred.text))
#class(lda.pred.text)
# Going from a factor to as.numeric return 207 only. This is wrong. Fix it
levels(factor(ifelse(as.numeric(lda.pred.text$class) > mean(as.numeric(lda.pred.text$class),na.rm=TRUE), "1","0")))
levels(factor(ifelse(test_text$found_helpful_percentage > mean(test_text$found_helpful_percentage,na.rm=TRUE), "1","0")))
confusionMatrix(factor(ifelse(as.numeric(lda.pred.text$class) > mean(as.numeric(lda.pred.text$class),na.rm=TRUE), "1","0")), factor(ifelse(test_text$found_helpful_percentage > mean(test_text$found_helpful_percentage,na.rm=TRUE), "1","0")), positive = "1")
