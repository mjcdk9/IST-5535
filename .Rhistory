?col
?color
??color
?col
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load ISLR package
library(ISLR)
# Structure of the Default dataset
str(Default)
head(Default)
summary(Default)
# Frequency of default
table(Default$default)
library(ggplot2)
qplot(x=default, y=balance, data = Default, col= default, main = 'Boxplot 1') +
geom_boxplot()
qplot(x=student, y=balance, data = Default, col= student, main = 'Boxplot 2') +
geom_boxplot()
qplot(x=default, y=income, data = Default, col= default, main = 'Boxplot 3') +
geom_boxplot()
mosaicplot(~ student + default, data=Default, main = "Mosaic Plot", col='lightblue')
pairs(~default + balance + income + student, data = Default, col = Default$default)
# Logistic regression
logit1.fit <- glm(default ~ balance,
family=binomial(link='logit'),data = Default)
summary(logit1.fit)
# Calculate predicted probability
logit1.prob <- predict(logit1.fit, type = "response")
plot(x = Default$balanc, y = ifelse(Default$default == "Yes", 1, 0),
col = "orange", xlab = "Balance", ylab = "Probability of Default")
points(x = Default$balance[order(Default$balance)],
y = logit1.prob[order(Default$balance)],
type = "l", col="blue", lwd = 2)
# Logistic regression
logit2.fit <- glm(default ~ student,
family=binomial(link='logit'),data = Default)
summary(logit2.fit)
# Logistic regression
logit3.fit <- glm(default ~ balance + student,
family=binomial(link='logit'),data = Default)
summary(logit3.fit)
# Logistic regression
logit.fit <- glm(default ~ balance + income + student,
family=binomial(link='logit'),data = Default)
summary(logit.fit)
# Get coefficient estimates
coef(logit.fit)
# Get coefficient estimates with statistics
summary(logit.fit)$coef
# Get p-values for all coefficient estimates
summary(logit.fit)$coef[,4]
library(stargazer)
stargazer(logit1.fit, logit2.fit, logit3.fit, logit.fit,
type = "text",star.cutoffs = c(0.05, 0.01, 0.001),
title="Logistic Regression", digits=4)
# McFadden R2
# install.packages("pscl")
library(pscl)
pR2(logit.fit)
?pRZ
?pRZ()
# Fit the null model
logit.null.fit <- glm(default ~1,family=binomial(link='logit'),data=Default)
# Show the log likelihood of the null model
logLik(logit.null.fit)
# Manually calculate McFadden pseudo R squared
cat("McFadden pseudo R2 = ", 1-logLik(logit.fit)/logLik(logit.null.fit))
# Calculate probability of default
logit.probs <- predict(logit.fit,type="response")
# Show the first 10 values
logit.probs[1:10]
# Calculate predicted default
logit.pred <- ifelse(logit.probs >.5, "Yes", "No")
# Show confusion matrix
table(Prediction=logit.pred, Truth=Default$default)
# Calculate in-sample prediction accuracy
mean(logit.pred == Default$default)
# Show confusion matrix
table(Prediction=logit.pred, Truth=Default$default)
library(caret)
library(caret)
confusionMatrix(factor(logit.pred),Default$default, positive = "Yes")
confusionMatrix(factor(logit.pred),Default$default, positive = "Yes")
library(e1071)
install.packages(e1071)
install.packages("e1071")
install.packages("e1071")
library(e1071)
confusionMatrix(factor(logit.pred),Default$default, positive = "Yes")
sensitivity(factor(logit.pred),Default$default, positive = "Yes")
specificity(factor(logit.pred),Default$default, negative = "No")
# Data partition: randomly split the dataset into a train (70%) and a test set (30%)
index <- 1:nrow(Default)
index
sample(index,)
sample(index,2)
sample(index,2)
sample(index,2)
sample(index,2)
sample(index,2)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
sample(index,20)
set.seed(123)
sample(index,20)
sample(index,20)
set.seed(123)
sample(index,20)
set.seed(123)
sample(index,20)
round(length(index)*0.7)
# Data partition: randomly split the dataset into a train (70%) and a test set (30%)
index <- 1:nrow(Default)
set.seed(123)
train_index <- sample(index, round(length(index)*0.7))
train_set <- Default[train_index,]
test_set <- Default[-train_index,]
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load ISLR package
library(ISLR)
# Structure of the Default dataset
str(Default)
head(Default)
summary(Default)
# Frequency of default
table(Default$default)
library(ggplot2)
qplot(x=default, y=balance, data = Default, col= default, main = 'Boxplot 1') +
geom_boxplot()
qplot(x=student, y=balance, data = Default, col= student, main = 'Boxplot 2') +
geom_boxplot()
qplot(x=default, y=income, data = Default, col= default, main = 'Boxplot 3') +
geom_boxplot()
mosaicplot(~ student + default, data=Default, main = "Mosaic Plot", col='lightblue')
pairs(~default + balance + income + student, data = Default, col = Default$default)
# Logistic regression
logit1.fit <- glm(default ~ balance,
family=binomial(link='logit'),data = Default)
summary(logit1.fit)
# Calculate predicted probability
logit1.prob <- predict(logit1.fit, type = "response")
plot(x = Default$balanc, y = ifelse(Default$default == "Yes", 1, 0),
col = "orange", xlab = "Balance", ylab = "Probability of Default")
points(x = Default$balance[order(Default$balance)],
y = logit1.prob[order(Default$balance)],
type = "l", col="blue", lwd = 2)
# Logistic regression
logit2.fit <- glm(default ~ student,
family=binomial(link='logit'),data = Default)
summary(logit2.fit)
# Logistic regression
logit3.fit <- glm(default ~ balance + student,
family=binomial(link='logit'),data = Default)
summary(logit3.fit)
# Logistic regression
logit.fit <- glm(default ~ balance + income + student,
family=binomial(link='logit'),data = Default)
summary(logit.fit)
# Get coefficient estimates
coef(logit.fit)
# Get coefficient estimates with statistics
summary(logit.fit)$coef
# Get p-values for all coefficient estimates
summary(logit.fit)$coef[,4]
library(stargazer)
stargazer(logit1.fit, logit2.fit, logit3.fit, logit.fit,
type = "text",star.cutoffs = c(0.05, 0.01, 0.001),
title="Logistic Regression", digits=4)
# McFadden R2
# install.packages("pscl")
library(pscl)
pR2(logit.fit)
# Fit the null model
logit.null.fit <- glm(default ~1,family=binomial(link='logit'),data=Default)
# Show the log likelihood of the null model
logLik(logit.null.fit)
# Manually calculate McFadden pseudo R squared
cat("McFadden pseudo R2 = ", 1-logLik(logit.fit)/logLik(logit.null.fit))
# Calculate probability of default
logit.probs <- predict(logit.fit,type="response")
# Show the first 10 values
logit.probs[1:10]
# Calculate predicted default
logit.pred <- ifelse(logit.probs >.5, "Yes", "No")
# Show confusion matrix
table(Prediction=logit.pred, Truth=Default$default)
# Calculate in-sample prediction accuracy
mean(logit.pred == Default$default)
library(caret)
library(e1071)
confusionMatrix(factor(logit.pred),Default$default, positive = "Yes")
sensitivity(factor(logit.pred),Default$default, positive = "Yes")
specificity(factor(logit.pred),Default$default, negative = "No")
# Data partition: randomly split the dataset into a train (70%) and a test set (30%)
index <- 1:nrow(Default)
set.seed(123)
train_index <- sample(index, round(length(index)*0.7))
train_set <- Default[train_index,]
test_set <- Default[-train_index,]
str(train_set)
str(test_set)
# Train the logistic regression model
logit.fit.train <- glm(default ~ balance + income + student,
family=binomial(link='logit'),data = train_set)
summary(logit.fit.train)
stargazer(logit.fit, logit.fit.train, type = "text",star.cutoffs = c(0.05, 0.01, 0.001),
title="Logistic Regression", digits=4)
# Calculate probability of default
test_probs <- predict(logit.fit.train, newdata = test_set, type="response")
# Show the first 10 values
test_probs[1:10]
# Calculate predicted default
test_pred <- ifelse(test_probs >.5, "Yes", "No")
# Show confusion matrix
confusionMatrix(factor(test_pred),test_set$default)
library(MASS)
lda.fit=lda(default ~ balance + income + student, data = Default)
lda.fit
# Show coefficients of linear discriminants
lda.fit$scaling
plot(lda.fit)
lda.pred=predict(lda.fit)
names(lda.pred)
plot(lda.pred$x, lda.pred$class,
col=c("green","red")[Default$default],
xlab = 'LD1', ylab = 'Predicted Class')
```{r}
confusionMatrix(lda.pred$class,Default$default, positive = "Yes")
# Calculate in-sample prediction accuracy
mean(lda.pred$class == Default$default)
# Calculate in-sample prediction accuracy
mean(lda.pred$class == Default$default)
sum(lda.pred$posterior[,2]>=.5)
sum(lda.pred$posterior[,2]<.5)
lda.pred$posterior[1:20,2]
lda.pred$class[1:20]
